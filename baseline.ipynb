{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"prithivMLmods/Deep-Fake-Detector-v2-Model\"\n",
    "TEST_DIR = Path(\"./test_data\")  # test 데이터 경로\n",
    "\n",
    "# Submission\n",
    "OUTPUT_DIR = Path(\"./output\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)  # output 폴더 없으면 생성\n",
    "\n",
    "OUT_CSV = OUTPUT_DIR / \"baseline_submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_EXTS = {\".jpg\", \".jpeg\", \".png\", \".jfif\"}\n",
    "VIDEO_EXTS = {\".mp4\", \".mov\"}\n",
    "\n",
    "TARGET_SIZE = (224, 224)\n",
    "NUM_FRAMES = 10  # 비디오 샘플링 프레임 수\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_frame_indices(total_frames: int, num_frames: int) -> np.ndarray:\n",
    "    \"\"\"비디오 프레임을 균등하게 샘플링\"\"\"\n",
    "    if total_frames <= 0:\n",
    "        return np.array([], dtype=int)\n",
    "    if total_frames <= num_frames:\n",
    "        return np.arange(total_frames, dtype=int)\n",
    "    return np.linspace(0, total_frames - 1, num_frames, dtype=int)\n",
    "\n",
    "def get_full_frame_padded(pil_img: Image.Image, target_size=(224, 224)) -> Image.Image:\n",
    "    \"\"\"전체 이미지를 비율 유지하며 정사각형 패딩 처리\"\"\"\n",
    "    img = pil_img.convert(\"RGB\")\n",
    "    img.thumbnail(target_size, Image.BICUBIC)\n",
    "    new_img = Image.new(\"RGB\", target_size, (0, 0, 0))\n",
    "    new_img.paste(img, ((target_size[0] - img.size[0]) // 2,\n",
    "                        (target_size[1] - img.size[1]) // 2))\n",
    "    return new_img\n",
    "\n",
    "def read_rgb_frames(file_path: Path, num_frames: int = NUM_FRAMES) -> List[np.ndarray]:\n",
    "    \"\"\"이미지 또는 비디오에서 RGB 프레임 추출\"\"\"\n",
    "    ext = file_path.suffix.lower()\n",
    "    \n",
    "    # 이미지 파일\n",
    "    if ext in IMAGE_EXTS:\n",
    "        try:\n",
    "            img = Image.open(file_path).convert(\"RGB\")\n",
    "            return [np.array(img)]\n",
    "        except Exception:\n",
    "            return []\n",
    "    \n",
    "    # 비디오 파일\n",
    "    if ext in VIDEO_EXTS:\n",
    "        cap = cv2.VideoCapture(str(file_path))\n",
    "        total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        if total <= 0:\n",
    "            cap.release()\n",
    "            return []\n",
    "        \n",
    "        frame_indices = uniform_frame_indices(total, num_frames)\n",
    "        frames = []\n",
    "        \n",
    "        for idx in frame_indices:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, int(idx))\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                continue\n",
    "            frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        cap.release()\n",
    "        return frames\n",
    "    \n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessOutput:\n",
    "    def __init__(\n",
    "        self,\n",
    "        filename: str,\n",
    "        imgs: List[Image.Image],\n",
    "        error: Optional[str] = None\n",
    "    ):\n",
    "        self.filename = filename\n",
    "        self.imgs = imgs\n",
    "        self.error = error\n",
    "\n",
    "def preprocess_one(file_path: Path, num_frames: int = NUM_FRAMES) -> PreprocessOutput:\n",
    "    \"\"\"\n",
    "    파일 하나에 대한 전처리 수행\n",
    "    \n",
    "    Args:\n",
    "        file_path: 처리할 파일 경로\n",
    "        num_frames: 비디오에서 추출할 프레임 수\n",
    "    \n",
    "    Returns:\n",
    "        PreprocessOutput 객체\n",
    "    \"\"\"\n",
    "    try:\n",
    "        frames = read_rgb_frames(file_path, num_frames=num_frames)\n",
    "              \n",
    "        imgs: List[Image.Image] = []\n",
    "        \n",
    "        for rgb in frames:     \n",
    "            imgs.append(get_full_frame_padded(Image.fromarray(rgb), TARGET_SIZE))\n",
    "        \n",
    "        return PreprocessOutput(file_path.name, imgs, None)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return PreprocessOutput(file_path.name, [], str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading model...\")\n",
    "model = ViTForImageClassification.from_pretrained(MODEL_ID).to(DEVICE)\n",
    "processor = ViTImageProcessor.from_pretrained(MODEL_ID)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model loaded: {MODEL_ID}\")\n",
    "print(f\"Model config: num_labels={model.config.num_labels}\")\n",
    "if hasattr(model.config, 'id2label'):\n",
    "    print(f\"id2label: {model.config.id2label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face_regions(image: Image.Image) -> List[Image.Image]:\n",
    "    \"\"\"얼굴 영역만 추출하여 deepfake 감지 강화\"\"\"\n",
    "    import mediapipe as mp\n",
    "    mp_face_detection = mp.solutions.face_detection\n",
    "    \n",
    "    face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.5)\n",
    "    \n",
    "    img_array = np.array(image)\n",
    "    results = face_detection.process(cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    face_images = []\n",
    "    h, w, _ = img_array.shape\n",
    "    \n",
    "    if results.detections:\n",
    "        for detection in results.detections:\n",
    "            bbox = detection.location_data.relative_bounding_box\n",
    "            x_min = max(0, int(bbox.xmin * w) - 10)\n",
    "            y_min = max(0, int(bbox.ymin * h) - 10)\n",
    "            x_max = min(w, int((bbox.xmin + bbox.width) * w) + 10)\n",
    "            y_max = min(h, int((bbox.ymin + bbox.height) * h) + 10)\n",
    "            \n",
    "            face_crop = image.crop((x_min, y_min, x_max, y_max))\n",
    "            face_crop = face_crop.resize(TARGET_SIZE, Image.BICUBIC)\n",
    "            face_images.append(face_crop)\n",
    "    \n",
    "    return face_images if face_images else [image]\n",
    "\n",
    "def apply_laplacian_filter(image: Image.Image) -> np.ndarray:\n",
    "    \"\"\"라플라시안 필터로 고주파 성분 강조 (deepfake 특징 강화)\"\"\"\n",
    "    img_array = np.array(image, dtype=np.float32) / 255.0\n",
    "    \n",
    "    # 라플라시안 필터 적용\n",
    "    laplacian_kernel = np.array([[0, -1, 0],\n",
    "                                 [-1, 4, -1],\n",
    "                                 [0, -1, 0]], dtype=np.float32)\n",
    "    \n",
    "    if len(img_array.shape) == 3:  # RGB\n",
    "        laplacian = cv2.filter2D(img_array[:,:,0], -1, laplacian_kernel)\n",
    "    else:\n",
    "        laplacian = cv2.filter2D(img_array, -1, laplacian_kernel)\n",
    "    \n",
    "    laplacian = np.clip(laplacian, 0, 1)\n",
    "    return laplacian\n",
    "\n",
    "def infer_fake_probs(pil_images: List[Image.Image]) -> List[float]:\n",
    "    if not pil_images:\n",
    "        return []\n",
    "\n",
    "    probs: List[float] = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        inputs = processor(images=pil_images, return_tensors=\"pt\")\n",
    "        inputs = {k: v.to(DEVICE, non_blocking=True) for k, v in inputs.items()}\n",
    "        logits = model(**inputs).logits\n",
    "        batch_probs = F.softmax(logits, dim=1)[:, 1]\n",
    "        probs.extend(batch_probs.cpu().tolist())\n",
    "\n",
    "    return probs\n",
    "\n",
    "def infer_with_multi_scale(pil_images: List[Image.Image]) -> List[float]:\n",
    "    \"\"\"다양한 크기로 추론하여 정확도 향상\"\"\"\n",
    "    if not pil_images:\n",
    "        return []\n",
    "    \n",
    "    all_probs = []\n",
    "    \n",
    "    # 원본 크기\n",
    "    all_probs.extend(infer_fake_probs(pil_images))\n",
    "    \n",
    "    # 작은 크기 (저주파 특징)\n",
    "    small_images = [img.resize((112, 112), Image.BICUBIC) for img in pil_images]\n",
    "    small_probs = infer_fake_probs(small_images)\n",
    "    all_probs.extend(small_probs)\n",
    "    \n",
    "    # 큰 크기 (세부 특징)\n",
    "    large_images = [img.resize((336, 336), Image.BICUBIC) for img in pil_images]\n",
    "    large_probs = infer_fake_probs(large_images)\n",
    "    all_probs.extend(large_probs)\n",
    "    \n",
    "    return all_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted([p for p in TEST_DIR.iterdir() if p.is_file()])\n",
    "print(f\"Test data length: {len(files)}\")\n",
    "\n",
    "results: Dict[str, float] = {}\n",
    "\n",
    "# 전처리 및 추론 (개선된 버전)\n",
    "for file_path in tqdm(files, desc=\"Processing\"):\n",
    "    out = preprocess_one(file_path)\n",
    "    \n",
    "    # 1. 에러 로깅\n",
    "    if out.error:\n",
    "        print(f\"[WARN] {out.filename}: {out.error}\")\n",
    "        results[out.filename] = 0.0\n",
    "    \n",
    "    # 2. 정상 추론\n",
    "    elif out.imgs:\n",
    "        # Multi-scale 추론으로 더 정확한 판단\n",
    "        all_probs = infer_with_multi_scale(out.imgs)\n",
    "        \n",
    "        if all_probs:\n",
    "            # 다양한 통계를 활용한 앙상블\n",
    "            mean_prob = float(np.mean(all_probs))\n",
    "            max_prob = float(np.max(all_probs))\n",
    "            \n",
    "            # 가중 평균: 최대값에 더 높은 가중치\n",
    "            weighted_prob = mean_prob * 0.4 + max_prob * 0.6\n",
    "            results[out.filename] = weighted_prob\n",
    "        else:\n",
    "            results[out.filename] = 0.0\n",
    "    \n",
    "    # 3. 둘 다 없으면 0.0 (real)\n",
    "    else:\n",
    "        results[out.filename] = 0.0\n",
    "\n",
    "print(f\"Inference completed. Processed: {len(results)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./sample_submission.csv')\n",
    "submission['prob'] = submission['filename'].map(results).fillna(0.0)\n",
    "\n",
    "# CSV 저장\n",
    "submission.to_csv(OUT_CSV, encoding='utf-8-sig', index=False)\n",
    "print(f\"Saved submission to: {OUT_CSV}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
