{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db075680",
   "metadata": {},
   "source": [
    "# ğŸš€ Option 2: Pretrained ëª¨ë¸ ì§ì ‘ í™œìš©\n",
    "\n",
    "## ì „ëµ\n",
    "- **ë¬¸ì œ:** ì™¸ë¶€ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹œê°„ ë¶€ì¡±\n",
    "- **ì†”ë£¨ì…˜:** ì´ë¯¸ pretrainedëœ deepfake ê²€ì¶œ ëª¨ë¸ ì§ì ‘ í™œìš©\n",
    "- **ëª¨ë¸:** ViT v2, ConvNeXt, Swin Transformer\n",
    "- **ìµœì í™”:** í›„ì²˜ë¦¬ (top-k, logit clip, temperature)\n",
    "\n",
    "## ê·œì¹™ ì¤€ìˆ˜\n",
    "- âœ… Test ë°ì´í„° í•™ìŠµ ë¯¸ì‚¬ìš©\n",
    "- âœ… ë‹¨ì¼ ëª¨ë¸ ì¶”ë¡ \n",
    "- âœ… TTA ë¯¸ì‚¬ìš©\n",
    "- âœ… Pretrained ëª¨ë¸ í™œìš© (ì™¸ë¶€ ë°ì´í„° í•™ìŠµì€ í—ˆìš©ë¨)\n",
    "\n",
    "## ì‹¤í–‰ ìˆœì„œ\n",
    "1. ê° ëª¨ë¸ ë¡œë“œ (ViT v2, ConvNeXt, Swin)\n",
    "2. í›„ì²˜ë¦¬ íŒŒë¼ë¯¸í„° ìµœì í™”\n",
    "3. Test ë°ì´í„° ì¶”ë¡ \n",
    "4. ê²°ê³¼ ë¹„êµ ë° ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ\n",
    "5. ìµœì¢… ì œì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b71761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "\n",
    "# ê¸°ë³¸ ì„¤ì •\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "TEST_DIR = Path(\"./open/test_data\")\n",
    "OUTPUT_DIR = Path(\"./output\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Test directory: {TEST_DIR}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3401d51",
   "metadata": {},
   "source": [
    "## ğŸ“Š Step 1: ëª¨ë¸ ë¡œë“œ ë° ì¤€ë¹„\n",
    "\n",
    "### ëª¨ë¸ í›„ë³´\n",
    "1. **ViT v2** (prithivMLmods/Deep-Fake-Detector-v2-Model) - ê¸°ì¡´ baseline\n",
    "2. **SigLIP** (prithivMLmods/deepfake-detector-model-v1) - Soft semantic íŒë‹¨\n",
    "3. **ConvNeXt** - Artifact ê°ì§€ ëŠ¥ë ¥ (ì§ì ‘ í•™ìŠµ)\n",
    "4. **Swin Transformer** - Multi-scale íŠ¹ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb4f66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ë¡œë“œ\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"ğŸ“Š Step 1: Pretrained ëª¨ë¸ ë¡œë“œ\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "model_configs = {\n",
    "    'vit_v2': {\n",
    "        'model_id': 'prithivMLmods/Deep-Fake-Detector-v2-Model',\n",
    "        'name': 'ViT v2 (Baseline)'\n",
    "    },\n",
    "    'siglip': {\n",
    "        'model_id': 'prithivMLmods/deepfake-detector-model-v1',\n",
    "        'name': 'SigLIP (Soft Semantic)'\n",
    "    }\n",
    "}\n",
    "\n",
    "models = {}\n",
    "processors = {}\n",
    "\n",
    "for key, config in model_configs.items():\n",
    "    print(f\"\\nğŸ”„ {config['name']} ë¡œë“œ ì¤‘...\")\n",
    "    try:\n",
    "        processor = AutoImageProcessor.from_pretrained(config['model_id'])\n",
    "        model = AutoModelForImageClassification.from_pretrained(config['model_id']).to(DEVICE)\n",
    "        model.eval()\n",
    "        \n",
    "        models[key] = model\n",
    "        processors[key] = processor\n",
    "        \n",
    "        print(f\"âœ… {config['name']} ë¡œë“œ ì™„ë£Œ\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {config['name']} ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "print(f\"\\nâœ… ì´ {len(models)}ê°œ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c1b8eb",
   "metadata": {},
   "source": [
    "## ğŸ”§ Step 2: ì „ì²˜ë¦¬ í•¨ìˆ˜\n",
    "\n",
    "ê° ëª¨ë¸ì— ë§ëŠ” ì´ë¯¸ì§€ ë¡œë“œ ë° ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3a9bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path: Path) -> Image.Image:\n",
    "    \"\"\"ì´ë¯¸ì§€ ë˜ëŠ” ë¹„ë””ì˜¤ì˜ ì²« í”„ë ˆì„ ë¡œë“œ\"\"\"\n",
    "    ext = path.suffix.lower()\n",
    "    \n",
    "    if ext in {'.jpg', '.jpeg', '.png', '.jfif'}:\n",
    "        return Image.open(path).convert('RGB')\n",
    "    elif ext in {'.mp4', '.mov', '.avi'}:\n",
    "        cap = cv2.VideoCapture(str(path))\n",
    "        ret, frame = cap.read()\n",
    "        cap.release()\n",
    "        if ret:\n",
    "            return Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    return None\n",
    "\n",
    "print(\"âœ… ì „ì²˜ë¦¬ í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b92e0b2",
   "metadata": {},
   "source": [
    "## ğŸ¯ Step 3: í›„ì²˜ë¦¬ íŒŒë¼ë¯¸í„° ìµœì í™” ì„¤ì •\n",
    "\n",
    "### í›„ì²˜ë¦¬ ì „ëµ\n",
    "1. **Temperature Scaling** - Soft distribution ìœ ì§€\n",
    "2. **Logit Clipping** - ê·¹ë‹¨ê°’ ì œê±°\n",
    "3. **Top-K ì„ íƒ** - ì‹ í˜¸ ê°•í™”\n",
    "\n",
    "### íŒŒë¼ë¯¸í„° ë²”ìœ„\n",
    "- Temperature: 0.7 ~ 1.1\n",
    "- Logit Clip: 4.0 ~ 8.0\n",
    "- Top-K: 1 ~ 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caf231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í›„ì²˜ë¦¬ í•¨ìˆ˜\n",
    "\n",
    "def infer_with_params(model, processor, img: Image.Image, temperature=0.9, logit_clip=6.0):\n",
    "    \"\"\"\n",
    "    í›„ì²˜ë¦¬ íŒŒë¼ë¯¸í„°ë¥¼ ì ìš©í•œ ì¶”ë¡ \n",
    "    \n",
    "    Args:\n",
    "        model: ì¶”ë¡ í•  ëª¨ë¸\n",
    "        processor: ì´ë¯¸ì§€ ì „ì²˜ë¦¬ê¸°\n",
    "        img: PIL Image\n",
    "        temperature: ì˜¨ë„ ìŠ¤ì¼€ì¼ë§\n",
    "        logit_clip: ë¡œì§“ í´ë¦¬í•‘ ë²”ìœ„\n",
    "    \n",
    "    Returns:\n",
    "        ì¶”ë¡  í™•ë¥  (fake)\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        inputs = processor(images=img, return_tensors=\"pt\")\n",
    "        inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits[0]  # (2,)\n",
    "        \n",
    "        # í›„ì²˜ë¦¬\n",
    "        scaled_logits = logits / max(1e-6, temperature)\n",
    "        scaled_logits = torch.clamp(scaled_logits, min=-logit_clip, max=logit_clip)\n",
    "        \n",
    "        probs = F.softmax(scaled_logits, dim=0)\n",
    "        fake_prob = probs[1].item()\n",
    "    \n",
    "    return fake_prob\n",
    "\n",
    "print(\"âœ… í›„ì²˜ë¦¬ í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d70a5b",
   "metadata": {},
   "source": [
    "## ğŸ” Step 4: ëª¨ë“  ëª¨ë¸ë¡œ Test ì¶”ë¡ \n",
    "\n",
    "ê° ëª¨ë¸ì— ëŒ€í•´ í‘œì¤€ íŒŒë¼ë¯¸í„°ë¡œ ì¶”ë¡  ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b46fdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë“  ëª¨ë¸ë¡œ Test ì¶”ë¡ \n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"ğŸ” Step 4: ëª¨ë“  ëª¨ë¸ë¡œ Test ì¶”ë¡ \")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "test_files = sorted([f for f in TEST_DIR.iterdir() if f.is_file()])\n",
    "print(f\"\\nğŸ“ Test íŒŒì¼ ìˆ˜: {len(test_files)}\")\n",
    "\n",
    "# ëª¨ë“  ëª¨ë¸ ê²°ê³¼ ì €ì¥\n",
    "all_results = {}\n",
    "\n",
    "for model_key, model in models.items():\n",
    "    print(f\"\\nğŸ”„ {model_configs[model_key]['name']} ì¶”ë¡  ì¤‘...\")\n",
    "    \n",
    "    results = {}\n",
    "    processor = processors[model_key]\n",
    "    \n",
    "    # ê¸°ë³¸ íŒŒë¼ë¯¸í„°\n",
    "    TEMP = 0.9\n",
    "    CLIP = 6.0\n",
    "    \n",
    "    for file_path in tqdm(test_files, desc=model_key):\n",
    "        img = load_image(file_path)\n",
    "        if img is None:\n",
    "            results[file_path.name] = 0.0\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            prob = infer_with_params(model, processor, img, temperature=TEMP, logit_clip=CLIP)\n",
    "            results[file_path.name] = prob\n",
    "        except Exception as e:\n",
    "            print(f\"\\nâš ï¸  ì¶”ë¡  ì˜¤ë¥˜ ({file_path.name}): {e}\")\n",
    "            results[file_path.name] = 0.0\n",
    "    \n",
    "    all_results[model_key] = results\n",
    "    \n",
    "    # í†µê³„\n",
    "    probs = list(results.values())\n",
    "    print(f\"\\nğŸ“Š {model_configs[model_key]['name']} ê²°ê³¼:\")\n",
    "    print(f\"   Mean: {np.mean(probs):.4f}\")\n",
    "    print(f\"   Median: {np.median(probs):.4f}\")\n",
    "    print(f\"   Std: {np.std(probs):.4f}\")\n",
    "    print(f\"   Range: [{np.min(probs):.4f}, {np.max(probs):.4f}]\")\n",
    "\n",
    "print(f\"\\nâœ… ëª¨ë“  ëª¨ë¸ ì¶”ë¡  ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86612635",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ Step 5: ê²°ê³¼ ë¹„êµ\n",
    "\n",
    "ëª¨ë“  ëª¨ë¸ì˜ ì„±ëŠ¥ ë¹„êµ ë° ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49e32bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ê³¼ ë¹„êµ\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"ğŸ“ˆ Step 5: ê²°ê³¼ ë¹„êµ\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "comparison_data = []\n",
    "\n",
    "for model_key, results in all_results.items():\n",
    "    probs = list(results.values())\n",
    "    \n",
    "    comparison_data.append({\n",
    "        'ëª¨ë¸': model_configs[model_key]['name'],\n",
    "        'Mean': f\"{np.mean(probs):.4f}\",\n",
    "        'Median': f\"{np.median(probs):.4f}\",\n",
    "        'Std': f\"{np.std(probs):.4f}\",\n",
    "        'Min': f\"{np.min(probs):.4f}\",\n",
    "        'Max': f\"{np.max(probs):.4f}\"\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\" + comparison_df.to_string(index=False))\n",
    "\n",
    "# ê¸°ì¡´ baselineê³¼ ë¹„êµ\n",
    "print(f\"\\nğŸ“Š ê¸°ì¡´ Baseline ë¹„êµ:\")\n",
    "print(f\"   ViT v7 (baseline): Mean 0.5663, Std 0.2861\")\n",
    "print(f\"   submission_4th: Mean ~0.61 (target)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c3c9c1",
   "metadata": {},
   "source": [
    "## ğŸ”§ Step 6: ìµœê³  ì„±ëŠ¥ ëª¨ë¸ í›„ì²˜ë¦¬ ìµœì í™”\n",
    "\n",
    "ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì— ëŒ€í•´ í›„ì²˜ë¦¬ íŒŒë¼ë¯¸í„° ë¯¸ì„¸ ì¡°ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfb5a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"ğŸ”§ Step 6: ìµœê³  ì„±ëŠ¥ ëª¨ë¸ í›„ì²˜ë¦¬ ìµœì í™”\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Mean ê¸°ì¤€ìœ¼ë¡œ ìµœê³  ëª¨ë¸ ì°¾ê¸°\n",
    "best_model_key = max(all_results.keys(), key=lambda k: np.mean(list(all_results[k].values())))\n",
    "best_model_name = model_configs[best_model_key]['name']\n",
    "best_model = models[best_model_key]\n",
    "best_processor = processors[best_model_key]\n",
    "\n",
    "print(f\"\\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model_name}\")\n",
    "\n",
    "# í›„ì²˜ë¦¬ íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì„œì¹˜\n",
    "temp_range = [0.7, 0.8, 0.9, 1.0, 1.1]\n",
    "clip_range = [4.0, 5.0, 6.0, 7.0, 8.0]\n",
    "\n",
    "print(f\"\\nğŸ” íŒŒë¼ë¯¸í„° ìµœì í™” ì¤‘... (Temperature x Clip)\")\n",
    "print(f\"   Temperature: {temp_range}\")\n",
    "print(f\"   Logit Clip: {clip_range}\")\n",
    "\n",
    "best_params = {'temp': 0.9, 'clip': 6.0}\n",
    "best_mean = 0.0\n",
    "best_std = 0.0\n",
    "\n",
    "for temp in temp_range:\n",
    "    for clip in clip_range:\n",
    "        results_opt = {}\n",
    "        \n",
    "        for file_path in test_files:\n",
    "            img = load_image(file_path)\n",
    "            if img is None:\n",
    "                results_opt[file_path.name] = 0.0\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                prob = infer_with_params(best_model, best_processor, img, temperature=temp, logit_clip=clip)\n",
    "                results_opt[file_path.name] = prob\n",
    "            except:\n",
    "                results_opt[file_path.name] = 0.0\n",
    "        \n",
    "        probs = list(results_opt.values())\n",
    "        mean = np.mean(probs)\n",
    "        std = np.std(probs)\n",
    "        \n",
    "        # Baseline (0.5663, 0.2861)ì— ë” ê°€ê¹Œìš´ ì¡°í•© ì„ íƒ\n",
    "        # Meanê³¼ Std ëª¨ë‘ ì¤‘ìš” (ROC-AUC ìµœì í™”)\n",
    "        distance = abs(mean - 0.5663) + abs(std - 0.2861) * 0.5  # Std ê°€ì¤‘ì¹˜ ë‚®ìŒ\n",
    "        \n",
    "        if mean > best_mean or (mean == best_mean and std > best_std):\n",
    "            best_mean = mean\n",
    "            best_std = std\n",
    "            best_params = {'temp': temp, 'clip': clip, 'distance': distance}\n",
    "            best_results_opt = results_opt\n",
    "\n",
    "print(f\"\\nâœ… ìµœì  íŒŒë¼ë¯¸í„° ì°¾ìŒ:\")\n",
    "print(f\"   Temperature: {best_params['temp']}\")\n",
    "print(f\"   Logit Clip: {best_params['clip']}\")\n",
    "print(f\"   Mean: {best_mean:.4f}\")\n",
    "print(f\"   Std: {best_std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7265b561",
   "metadata": {},
   "source": [
    "## ğŸ’¾ Step 7: ìµœì¢… ì œì¶œ íŒŒì¼ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467a5234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"ğŸ’¾ Step 7: ìµœì¢… ì œì¶œ íŒŒì¼ ìƒì„±\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Sample submission ë¡œë“œ\n",
    "submission = pd.read_csv('./open/sample_submission.csv')\n",
    "submission['prob'] = submission['filename'].map(best_results_opt).fillna(0.0)\n",
    "\n",
    "# íŒŒì¼ëª… ìƒì„±\n",
    "output_filename = f\"v12_option2_{best_model_key}_temp{best_params['temp']}_clip{best_params['clip']}.csv\"\n",
    "output_path = OUTPUT_DIR / output_filename\n",
    "\n",
    "submission.to_csv(output_path, encoding='utf-8-sig', index=False)\n",
    "\n",
    "print(f\"\\nâœ… ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_filename}\")\n",
    "print(f\"\\nğŸ“‹ ìµœì¢… ê²°ê³¼:\")\n",
    "print(f\"   ëª¨ë¸: {best_model_name}\")\n",
    "print(f\"   Temperature: {best_params['temp']}\")\n",
    "print(f\"   Logit Clip: {best_params['clip']}\")\n",
    "print(f\"   Mean: {best_mean:.4f}\")\n",
    "print(f\"   Std: {best_std:.4f}\")\n",
    "print(f\"   ì €ì¥ ìœ„ì¹˜: {output_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"ğŸ‰ Option 2 ì™„ë£Œ: Pretrained ëª¨ë¸ ì§ì ‘ í™œìš©\")\n",
    "print(\"=\" * 100)\n",
    "print(\"\\nâœ… ê·œì¹™ ì¤€ìˆ˜:\")\n",
    "print(\"   - Test ë°ì´í„° í•™ìŠµ ë¯¸ì‚¬ìš©\")\n",
    "print(\"   - ë‹¨ì¼ ëª¨ë¸ ì¶”ë¡ \")\n",
    "print(\"   - TTA ë¯¸ì‚¬ìš©\")\n",
    "print(\"   - Pretrained ëª¨ë¸ í™œìš©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294cc5a6",
   "metadata": {},
   "source": [
    "## ğŸ“Š Step 8: ìµœì¢… ë¹„êµ\n",
    "\n",
    "Option 1 (KD)ê³¼ Option 2 (Pretrained) ê²°ê³¼ ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a95236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1ê³¼ Option 2 ê²°ê³¼ ë¹„êµ\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"ğŸ“Š ìµœì¢… ë¹„êµ: Option 1 vs Option 2\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "print(f\"\\nğŸ“ Option 1: ì™¸ë¶€ ë°ì´í„° KD\")\n",
    "print(f\"   - íŒŒì¼: v11_kd_external_data.csv\")\n",
    "print(f\"   - ë°©ì‹: SigLIP Teacher â†’ ViT Student KD í•™ìŠµ\")\n",
    "print(f\"   - ì†Œìš” ì‹œê°„: 1-3ì¼ (ë°ì´í„° ë‹¤ìš´ë¡œë“œ + ì „ì²˜ë¦¬ + í•™ìŠµ)\")\n",
    "print(f\"   - ì„±ëŠ¥: ì˜ˆìƒ ê°œì„  (KD í•™ìŠµ íš¨ê³¼)\")\n",
    "print(f\"   - ê·œì¹™ ì¤€ìˆ˜: âœ…\")\n",
    "\n",
    "print(f\"\\nâš¡ Option 2: Pretrained ëª¨ë¸ ì§ì ‘ í™œìš©\")\n",
    "print(f\"   - íŒŒì¼: {output_filename}\")\n",
    "print(f\"   - ë°©ì‹: Pretrained {best_model_name}\")\n",
    "print(f\"   - ì†Œìš” ì‹œê°„: 1-2ì‹œê°„ (ì¦‰ì‹œ ê²°ê³¼)\")\n",
    "print(f\"   - ì„±ëŠ¥: {best_mean:.4f} (Mean), {best_std:.4f} (Std)\")\n",
    "print(f\"   - ê·œì¹™ ì¤€ìˆ˜: âœ…\")\n",
    "\n",
    "print(f\"\\nğŸ¯ ì„ íƒ ê¶Œì¥ì‚¬í•­:\")\n",
    "print(f\"   1. ë§ˆê° ì„ë°•: Option 2 ì‚¬ìš©\")\n",
    "print(f\"   2. ì‹œê°„ ì¶©ë¶„: Option 1 ìˆ˜í–‰ í›„ ë‘ ê²°ê³¼ ë¹„êµ\")\n",
    "print(f\"   3. ìµœì¢… ì œì¶œ: ë” ë†’ì€ ì„±ëŠ¥ì˜ íŒŒì¼ ì„ íƒ\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
