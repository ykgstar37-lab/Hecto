"""
Deepfake Detection - ë¹ ë¥¸ ì‹¤í–‰ ë²„ì „
"""

print("\n" + "="*80)
print("ğŸš€ Deepfake Detection ì¶”ë¡  ì‹œì‘")
print("="*80 + "\n")

# 1ë‹¨ê³„: ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ
print("[ì¤€ë¹„ 1/3] ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì¤‘...")
import random
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, List
import warnings
warnings.filterwarnings('ignore')

print("âœ“ ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ")

# 2ë‹¨ê³„: ì„¤ì •
print("[ì¤€ë¹„ 2/3] ì„¤ì • ì´ˆê¸°í™” ì¤‘...")
SEED = 42
random.seed(SEED)
np.random.seed(SEED)

TEST_DIR = Path("./open/test_data")
OUTPUT_DIR = Path("./output")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
OUT_CSV = OUTPUT_DIR / "baseline_enhanced_submission.csv"

print(f"âœ“ ì„¤ì • ì™„ë£Œ")
print(f"  - í…ŒìŠ¤íŠ¸ í´ë”: {TEST_DIR}")
print(f"  - ì¶œë ¥ í´ë”: {OUTPUT_DIR}")

# 3ë‹¨ê³„: ëª¨ë¸ ë¡œë“œ (ì§€ì—° ë¡œë“œ)
print("[ì¤€ë¹„ 3/3] ëª¨ë¸ ë¡œë“œ ì¤‘...")
try:
    import torch
    import torch.nn.functional as F
    from transformers import ViTForImageClassification, ViTImageProcessor
    from PIL import Image
    import cv2
    from tqdm import tqdm
    
    torch.manual_seed(SEED)
    torch.cuda.manual_seed_all(SEED)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    
    MODEL_ID = "prithivMLmods/Deep-Fake-Detector-v2-Model"
    DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
    
    print(f"  ëª¨ë¸ ë¡œë“œ ì¤‘... (ì´ ë¶€ë¶„ì´ 1-2ë¶„ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
    model = ViTForImageClassification.from_pretrained(MODEL_ID, trust_remote_code=True)
    model = model.to(DEVICE)
    processor = ViTImageProcessor.from_pretrained(MODEL_ID, trust_remote_code=True)
    model.eval()
    
    print(f"âœ“ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (Device: {DEVICE})")
    
except Exception as e:
    print(f"âœ— ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    print("\nëª¨ë¸ ë¡œë“œì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
    print("ë‹¤ìŒì„ ì‹œë„í•˜ì„¸ìš”:")
    print("1. python run_inference.py ì‹¤í–‰")
    print("2. ë˜ëŠ” baseline_enhanced.ipynbë¥¼ Jupyterì—ì„œ ì‹¤í–‰")
    exit(1)

# ============================================================================
# ì‹¤ì œ ì¶”ë¡ 
# ============================================================================

print("\n" + "="*80)
print("ğŸ”„ ì¶”ë¡  ìˆ˜í–‰ ì¤‘...")
print("="*80 + "\n")

# íŒŒì¼ ìˆ˜ì§‘
files = sorted([p for p in TEST_DIR.iterdir() if p.is_file()])
print(f"ğŸ“‚ í…ŒìŠ¤íŠ¸ íŒŒì¼: {len(files)}ê°œ\n")

IMAGE_EXTS = {".jpg", ".jpeg", ".png", ".jfif"}
VIDEO_EXTS = {".mp4", ".mov"}
TARGET_SIZE = (224, 224)
NUM_FRAMES = 15

def read_rgb_frames(file_path: Path, num_frames: int = NUM_FRAMES) -> List[np.ndarray]:
    ext = file_path.suffix.lower()
    if ext in IMAGE_EXTS:
        try:
            img = Image.open(file_path).convert("RGB")
            return [np.array(img)]
        except:
            return []
    if ext in VIDEO_EXTS:
        cap = cv2.VideoCapture(str(file_path))
        total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        if total <= 0:
            cap.release()
            return []
        frame_indices = np.linspace(0, total - 1, num_frames, dtype=int)
        frames = []
        for idx in frame_indices:
            cap.set(cv2.CAP_PROP_POS_FRAMES, int(idx))
            ret, frame = cap.read()
            if ret:
                frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        cap.release()
        return frames
    return []

def get_full_frame_padded(pil_img: Image.Image, target_size=(224, 224)) -> Image.Image:
    img = pil_img.convert("RGB")
    img.thumbnail(target_size, Image.BICUBIC)
    new_img = Image.new("RGB", target_size, (0, 0, 0))
    new_img.paste(img, ((target_size[0] - img.size[0]) // 2,
                        (target_size[1] - img.size[1]) // 2))
    return new_img

def infer_fake_probs(pil_images: List[Image.Image], batch_size: int = 8) -> List[float]:
    if not pil_images:
        return []
    probs = []
    for i in range(0, len(pil_images), batch_size):
        batch = pil_images[i:i+batch_size]
        with torch.inference_mode():
            inputs = processor(images=batch, return_tensors="pt")
            inputs = {k: v.to(DEVICE, non_blocking=True) for k, v in inputs.items()}
            logits = model(**inputs).logits
            batch_probs = F.softmax(logits, dim=1)[:, 1]
            probs.extend(batch_probs.cpu().tolist())
    return probs

results: Dict[str, float] = {}

for file_path in tqdm(files, desc="ì¶”ë¡ ", unit="íŒŒì¼"):
    try:
        frames = read_rgb_frames(file_path)
        imgs = []
        
        for rgb in frames:
            pil_img = get_full_frame_padded(Image.fromarray(rgb), TARGET_SIZE)
            imgs.append(pil_img)
        
        if imgs:
            # ê¸°ë³¸ ì¶”ë¡ 
            probs = infer_fake_probs(imgs)
            if probs:
                results[file_path.name] = float(np.mean(probs))
            else:
                results[file_path.name] = 0.0
        else:
            results[file_path.name] = 0.0
    except Exception as e:
        results[file_path.name] = 0.0

print(f"\nâœ“ ì¶”ë¡  ì™„ë£Œ: {len(results)}ê°œ íŒŒì¼ ì²˜ë¦¬ë¨\n")

# ============================================================================
# ì œì¶œ íŒŒì¼ ìƒì„±
# ============================================================================

print("ğŸ“ ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...\n")

submission = pd.read_csv('./open/sample_submission.csv')
submission['prob'] = submission['filename'].map(results).fillna(0.0)

# í†µê³„
print("ğŸ“Š ê²°ê³¼ í†µê³„:")
print(f"  â€¢ ìµœì†Œê°’: {submission['prob'].min():.4f}")
print(f"  â€¢ ìµœëŒ€ê°’: {submission['prob'].max():.4f}")
print(f"  â€¢ í‰ê· ê°’: {submission['prob'].mean():.4f}")
print(f"  â€¢ ì¤‘ì•™ê°’: {submission['prob'].median():.4f}")
print(f"  â€¢ Fake ì˜ˆì¸¡ (prob > 0.5): {(submission['prob'] > 0.5).sum()}ê°œ\n")

# CSV ì €ì¥
submission.to_csv(OUT_CSV, encoding='utf-8-sig', index=False)

print("="*80)
print(f"âœ… ì™„ë£Œ! ê²°ê³¼ íŒŒì¼: {OUT_CSV}")
print("="*80)
print(f"\nğŸ“¦ íŒŒì¼ í¬ê¸°: {OUT_CSV.stat().st_size:,} bytes")
print(f"ğŸ“‹ í–‰ ìˆ˜: {len(submission)}")
print(f"âœ¨ ê²°ê³¼ë¥¼ ì œì¶œí•˜ë©´ ì™„ë£Œë©ë‹ˆë‹¤!\n")
