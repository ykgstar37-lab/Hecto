"""
ê°„ë‹¨í•œ Deepfake Detection ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
"""

print("=" * 80)
print("ğŸš€ Deepfake Detection - ì¶”ë¡  ì‹œì‘")
print("=" * 80)

import os
os.environ['HF_HUB_DISABLE_SYMLINK_WARNING'] = '1'

print("\n[1/6] ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì¤‘...")
import random
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, List
import cv2
import torch
import torch.nn.functional as F
from PIL import Image
from tqdm import tqdm
print("âœ“ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ")

print("\n[2/6] ì„¤ì • ì´ˆê¸°í™” ì¤‘...")
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
torch.cuda.manual_seed_all(SEED)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

MODEL_ID = "prithivMLmods/Deep-Fake-Detector-v2-Model"
TEST_DIR = Path("./open/test_data")
OUTPUT_DIR = Path("./output")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
OUT_CSV = OUTPUT_DIR / "baseline_enhanced_submission.csv"

IMAGE_EXTS = {".jpg", ".jpeg", ".png", ".jfif"}
VIDEO_EXTS = {".mp4", ".mov"}
TARGET_SIZE = (224, 224)
NUM_FRAMES = 15
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print(f"âœ“ ì„¤ì • ì™„ë£Œ (Device: {DEVICE})")

print("\n[3/6] ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì •ì˜ ì¤‘...")

def uniform_frame_indices(total_frames: int, num_frames: int) -> np.ndarray:
    """ë¹„ë””ì˜¤ í”„ë ˆì„ì„ ê· ë“±í•˜ê²Œ ìƒ˜í”Œë§"""
    if total_frames <= 0:
        return np.array([], dtype=int)
    if total_frames <= num_frames:
        return np.arange(total_frames, dtype=int)
    return np.linspace(0, total_frames - 1, num_frames, dtype=int)

def get_full_frame_padded(pil_img: Image.Image, target_size=(224, 224)) -> Image.Image:
    """ì „ì²´ ì´ë¯¸ì§€ë¥¼ ë¹„ìœ¨ ìœ ì§€í•˜ë©° ì •ì‚¬ê°í˜• íŒ¨ë”© ì²˜ë¦¬"""
    img = pil_img.convert("RGB")
    img.thumbnail(target_size, Image.BICUBIC)
    new_img = Image.new("RGB", target_size, (0, 0, 0))
    new_img.paste(img, ((target_size[0] - img.size[0]) // 2,
                        (target_size[1] - img.size[1]) // 2))
    return new_img

def read_rgb_frames(file_path: Path, num_frames: int = NUM_FRAMES) -> List[np.ndarray]:
    """ì´ë¯¸ì§€ ë˜ëŠ” ë¹„ë””ì˜¤ì—ì„œ RGB í”„ë ˆì„ ì¶”ì¶œ"""
    ext = file_path.suffix.lower()
    
    if ext in IMAGE_EXTS:
        try:
            img = Image.open(file_path).convert("RGB")
            return [np.array(img)]
        except Exception:
            return []
    
    if ext in VIDEO_EXTS:
        cap = cv2.VideoCapture(str(file_path))
        total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        if total <= 0:
            cap.release()
            return []
        
        frame_indices = uniform_frame_indices(total, num_frames)
        frames = []
        
        for idx in frame_indices:
            cap.set(cv2.CAP_PROP_POS_FRAMES, int(idx))
            ret, frame = cap.read()
            if not ret:
                continue
            frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        
        cap.release()
        return frames
    
    return []

def apply_gaussian_blur_difference(image: Image.Image) -> Image.Image:
    """ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ ì°¨ì´ë¥¼ ì´ìš©í•œ ê²½ê³„ ê°•ì¡°"""
    img_array = np.array(image, dtype=np.float32) / 255.0
    blurred = cv2.GaussianBlur(img_array, (5, 5), 0)
    diff = img_array - blurred
    sharpened = img_array + diff * 0.5
    sharpened = np.clip(sharpened, 0, 1)
    sharpened = (sharpened * 255).astype(np.uint8)
    return Image.fromarray(sharpened)

print("âœ“ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ")

print("\n[4/6] ëª¨ë¸ ë¡œë“œ ì¤‘...")
print(f"ëª¨ë¸: {MODEL_ID}")
from transformers import ViTForImageClassification, ViTImageProcessor
model = ViTForImageClassification.from_pretrained(MODEL_ID).to(DEVICE)
processor = ViTImageProcessor.from_pretrained(MODEL_ID)
model.eval()
print("âœ“ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

print("\n[5/6] ì¶”ë¡  í•¨ìˆ˜ ì •ì˜ ì¤‘...")

def infer_fake_probs(pil_images: List[Image.Image], batch_size: int = 32) -> List[float]:
    """ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì¶”ë¡ """
    if not pil_images:
        return []
    probs = []
    for i in range(0, len(pil_images), batch_size):
        batch = pil_images[i:i+batch_size]
        with torch.inference_mode():
            inputs = processor(images=batch, return_tensors="pt")
            inputs = {k: v.to(DEVICE, non_blocking=True) for k, v in inputs.items()}
            logits = model(**inputs).logits
            batch_probs = F.softmax(logits, dim=1)[:, 1]
            probs.extend(batch_probs.cpu().tolist())
    return probs

def infer_with_tta(pil_images: List[Image.Image]) -> float:
    """TTAë¥¼ ì‚¬ìš©í•œ ì•™ìƒë¸” ì¶”ë¡ """
    if not pil_images:
        return 0.0
    
    all_probs = []
    
    # ì›ë³¸
    all_probs.extend(infer_fake_probs(pil_images))
    
    # ì¢Œìš° ë°˜ì „
    flipped_images = [img.transpose(Image.FLIP_LEFT_RIGHT) for img in pil_images]
    all_probs.extend(infer_fake_probs(flipped_images))
    
    # ë‹¤ë¥¸ í•´ìƒë„
    small_images = [img.resize((200, 200), Image.BICUBIC) for img in pil_images]
    small_images = [get_full_frame_padded(img, TARGET_SIZE) for img in small_images]
    all_probs.extend(infer_fake_probs(small_images))
    
    if not all_probs:
        return 0.0
    
    mean_prob = float(np.mean(all_probs))
    max_prob = float(np.max(all_probs))
    std_prob = float(np.std(all_probs))
    
    ensemble_prob = mean_prob * 0.3 + max_prob * 0.5 + std_prob * 0.2
    return np.clip(ensemble_prob, 0, 1)

print("âœ“ ì¶”ë¡  í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ")

print("\n[6/6] ì¶”ë¡  ìˆ˜í–‰ ì¤‘...")
files = sorted([p for p in TEST_DIR.iterdir() if p.is_file()])
print(f"í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜: {len(files)}")

results: Dict[str, float] = {}

for file_path in tqdm(files, desc="ì²˜ë¦¬ ì¤‘"):
    try:
        frames = read_rgb_frames(file_path, num_frames=NUM_FRAMES)
        imgs = []
        
        for rgb in frames:
            pil_img = get_full_frame_padded(Image.fromarray(rgb), TARGET_SIZE)
            imgs.append(pil_img)
            sharpened_img = apply_gaussian_blur_difference(pil_img)
            sharpened_img = get_full_frame_padded(sharpened_img, TARGET_SIZE)
            imgs.append(sharpened_img)
        
        if imgs:
            prob = infer_with_tta(imgs)
            results[file_path.name] = prob
        else:
            results[file_path.name] = 0.0
    except Exception as e:
        print(f"[ê²½ê³ ] {file_path.name}: {str(e)}")
        results[file_path.name] = 0.0

print(f"âœ“ ì¶”ë¡  ì™„ë£Œ (ì²˜ë¦¬ëœ íŒŒì¼: {len(results)}ê°œ)")

print("\nì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...")
submission = pd.read_csv('./open/sample_submission.csv')
submission['prob'] = submission['filename'].map(results).fillna(0.0)

print(f"\nğŸ“Š í™•ë¥  í†µê³„:")
print(f"  ìµœì†Œê°’: {submission['prob'].min():.4f}")
print(f"  ìµœëŒ€ê°’: {submission['prob'].max():.4f}")
print(f"  í‰ê· ê°’: {submission['prob'].mean():.4f}")
print(f"  ì¤‘ì•™ê°’: {submission['prob'].median():.4f}")
print(f"  í‘œì¤€í¸ì°¨: {submission['prob'].std():.4f}")
print(f"  Fake (prob > 0.5): {(submission['prob'] > 0.5).sum()}ê°œ")

submission.to_csv(OUT_CSV, encoding='utf-8-sig', index=False)
print(f"\nâœ… ì €ì¥ ì™„ë£Œ: {OUT_CSV}")

print("\n" + "=" * 80)
print("âœ¨ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
print("=" * 80)
